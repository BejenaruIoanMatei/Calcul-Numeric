{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f09a0db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e27bc20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_function_and_point(F, x_point, x_range=(-15, 15), y_range=(-15, 15), resolution=100):\n",
    "    X = np.linspace(x_range[0], x_range[1], resolution)\n",
    "    Y = np.linspace(y_range[0], y_range[1], resolution)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    \n",
    "    # Evaluăm F pe grid\n",
    "    Z = np.array([[F(np.array([x, y])) for x, y in zip(row_x, row_y)] \n",
    "                  for row_x, row_y in zip(X, Y)])\n",
    "    \n",
    "    # Punctul de marcat\n",
    "    x1, x2 = x_point\n",
    "    z = F(x_point)\n",
    "\n",
    "    # Plotare\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.7)\n",
    "    ax.scatter(x1, x2, z, color='red', s=50, label=f'Punct: ({x1:.2f}, {x2:.2f}, {z:.2f})')\n",
    "\n",
    "    ax.set_title('Suprafața funcției și punctul F(x)')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_zlabel('F(x1, x2)')\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfca922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_approximativ(F, x, epsilon=1e-5):\n",
    "   \n",
    "    gradApprox = np.zeros_like(x)\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        xPlus = x.copy()\n",
    "        xPlus[i] += epsilon\n",
    "        xMinus = x.copy()\n",
    "        xMinus[i] -= epsilon\n",
    "        gradApprox[i] = (F(xPlus) - F(xMinus)) / (2 * epsilon)\n",
    "\n",
    "    return gradApprox\n",
    "\n",
    "def backtracking_line_search(F, x, grad, alpha=0.3, beta=0.8):\n",
    "    t = 1.0\n",
    "    while F(x - t * grad) > F(x) - alpha * t * np.dot(grad, grad):\n",
    "        t *= beta\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25929cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "gradient_descent_aproximativ() got an unexpected keyword argument 'epsilon'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     63\u001b[39m x = np.array([\u001b[32m1.0\u001b[39m, \u001b[32m1.0\u001b[39m])\n\u001b[32m     64\u001b[39m minim1, val_minim1, iteratii1 = gradient_descent_analitic(F, dF, x, bktls = \u001b[38;5;28;01mTrue\u001b[39;00m, epsilon=\u001b[32m1e-15\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m minim2, val_minim2, iteratii2 = \u001b[43mgradient_descent_aproximativ\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbktls\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPunct de minim cu gradient aproximativ:\u001b[39m\u001b[33m\"\u001b[39m, minim1)\n\u001b[32m     68\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mValoarea functiei in minim cu gradient aproximativ:\u001b[39m\u001b[33m\"\u001b[39m, val_minim1)\n",
      "\u001b[31mTypeError\u001b[39m: gradient_descent_aproximativ() got an unexpected keyword argument 'epsilon'"
     ]
    }
   ],
   "source": [
    "\n",
    "# intoarcem nr iteratii pt a compara convergenta\n",
    "def gradient_descent_analitic(F, dF, x0, bktls=False, epsilon=1e-5):\n",
    "    max_iter = 1000\n",
    "    epsilon = 1e-5\n",
    "    learning_rate = 0.01\n",
    "    x = x0.copy()\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        grad = dF(x)\n",
    "        if bktls:\n",
    "            learning_rate = backtracking_line_search(F, x, grad)\n",
    "        x_new = x - learning_rate * grad\n",
    "        if np.linalg.norm(x_new - x) < epsilon:\n",
    "            return x_new, F(x_new), i + 1  \n",
    "        x = x_new\n",
    "\n",
    "    return x, F(x), max_iter\n",
    "\n",
    "def gradient_descent_aproximativ(F, x0, bktls=False, epsilon=1e-5):\n",
    "    max_iter = 1000\n",
    "    epsilon = 1e-5\n",
    "    learning_rate = 0.01\n",
    "    x = x0.copy()\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        grad = gradient_approximativ(F,x)\n",
    "        if bktls:\n",
    "            learning_rate = backtracking_line_search(F, x, grad)\n",
    "        x_new = x - learning_rate * grad\n",
    "        if np.linalg.norm(x_new - x) < epsilon:\n",
    "            return x_new, F(x_new), i + 1  \n",
    "        x = x_new\n",
    "\n",
    "    return x, F(x), max_iter\n",
    "\n",
    "functii = [\n",
    "    lambda x1, x2:  x1**2 + x2**2 - 2*x1 - 4*x2,\n",
    "    lambda x1, x2:  3*(x1**2) - 12*x1 + 2*(x2**2) + 16 * x2 - 10,\n",
    "    lambda x1, x2:  x1**2 - 4*x1*x2 + 5*(x2**2) - 4*x2 + 3,\n",
    "    lambda x1, x2:  x1**2 * x2 - 2*x1*(x2**2) - 3*x1*x2 + 4,\n",
    "    lambda x1, x2:  -np.log(1+np.exp(x1-x2)) + x1 + x2 - np.log(1+np.exp(x1+x2)) \n",
    "]\n",
    "\n",
    "derivate = [\n",
    "    lambda x1, x2: [2*x1 - 2, 2*x2 - 4],\n",
    "    lambda x1, x2: [6*x1 - 12, 4*x2 + 16],\n",
    "    lambda x1, x2: [2*x1 - 4*x2, -4*x1 + 10*x2 - 4],\n",
    "    lambda x1, x2: [2*x1*x2 - 2*x2**2 - 3*x2, x1**2 - 4*x1*x2 - 3*x1],\n",
    "    lambda x1, x2: [\n",
    "        -np.exp(x1 - x2) / (1 + np.exp(x1 - x2)) + 1 - np.exp(x1 + x2) / (1 + np.exp(x1 + x2)),\n",
    "         np.exp(x1 - x2) / (1 + np.exp(x1 - x2)) + 1 - np.exp(x1 + x2) / (1 + np.exp(x1 + x2))\n",
    "    ]\n",
    "]\n",
    "\n",
    "def F(v):\n",
    "    x1, x2 = v\n",
    "    return functii[1](x1,x2)\n",
    "\n",
    "def dF(v):\n",
    "    x1, x2 = v\n",
    "    return np.array(derivate[1](x1,x2))\n",
    "\n",
    "x = np.array([1.0, 1.0])\n",
    "minim1, val_minim1, iteratii1 = gradient_descent_analitic(F, dF, x, bktls = True, epsilon=1e-15)\n",
    "minim2, val_minim2, iteratii2 = gradient_descent_aproximativ(F, x, bktls = True, epsilon=1e-15)\n",
    "\n",
    "print(\"Punct de minim cu gradient aproximativ:\", minim1)\n",
    "print(\"Valoarea functiei in minim cu gradient aproximativ:\", val_minim1)\n",
    "print(\"Numar de iteratii cu gradient aproximativ:\", iteratii1)\n",
    "\n",
    "print(\"Punct de minim cu gradient analitic:\", minim2)\n",
    "print(\"Valoarea functiei in minim cu gradient analitic:\", val_minim2)\n",
    "print(\"Numar de iteratii cu gradient analitic:\", iteratii2)\n",
    "\n",
    "plot_function_and_point(F, minim1)\n",
    "plot_function_and_point(F, minim2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b7e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient analitic: [-6. 20.]\n",
      "Gradient aproximativ: [-6. 20.]\n"
     ]
    }
   ],
   "source": [
    "# Gradientul analitic e literalmente cel hardcodat \n",
    "grad_analitic = dF(x)\n",
    "print(\"Gradient analitic:\", grad_analitic)\n",
    "\n",
    "# Gradientul aproximativ e cel calculat prin metoda descrisa mai sus\n",
    "grad_aproximativ = gradient_approximativ(F, x)\n",
    "print(\"Gradient aproximativ:\", grad_aproximativ)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
